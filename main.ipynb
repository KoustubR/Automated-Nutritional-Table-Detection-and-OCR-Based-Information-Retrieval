{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from text_detection.text_detection import text_detection, load_text_model\n",
    "from text_detection.process import *\n",
    "from text_detection.regex import *\n",
    "from text_detection.nutrient_list import *\n",
    "from text_detection.spacial_map import *\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from crop import ImageCropper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image_obj, coords, saved_location, extend_ratio=0, SAVE=False):\n",
    "    nx = image_obj.shape[1]\n",
    "    ny = image_obj.shape[0]\n",
    "\n",
    "    modified_coords = (\n",
    "        int(coords[0] - extend_ratio * nx), \n",
    "        int(coords[1] - extend_ratio * ny), \n",
    "        int(coords[2] + extend_ratio * nx), \n",
    "        int(coords[3] + extend_ratio * ny)\n",
    "    )\n",
    "    cropped_image = image_obj[modified_coords[1]:modified_coords[3], modified_coords[0]:modified_coords[2]]\n",
    "\n",
    "    if SAVE:\n",
    "        cv2.imwrite(saved_location, cropped_image)\n",
    "\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IoULoss(tf.keras.losses.Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        intersection = tf.reduce_sum(tf.minimum(y_true, y_pred), axis=-1)\n",
    "        union = tf.reduce_sum(tf.maximum(y_true, y_pred), axis=-1)\n",
    "        iou = intersection / union\n",
    "        return 1 - iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(cropped_image, debug=False):\n",
    "    start_time = time.time() \n",
    "\n",
    "    cropped_image_cv = cv2.cvtColor(np.array(cropped_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    cropped_image_cv = preprocess_for_ocr(cropped_image_cv, 3)\n",
    "\n",
    "    if debug:\n",
    "        debug_folder = 'C:/Users/koust_fiminqv/Desktop/thesis/debug'\n",
    "        os.makedirs(debug_folder, exist_ok=True)\n",
    "        cv2.imwrite(os.path.join(debug_folder, 'output-opt.png'), cropped_image_cv)\n",
    "\n",
    "\n",
    "    text_blob_list = text_detection(cropped_image_cv)\n",
    "\n",
    "    if debug:\n",
    "        time_taken = time.time() - start_time\n",
    "        print(\"Time Taken to detect bounding boxes for text: %.5fs\" % time_taken)\n",
    "\n",
    "    text_location_list = []  \n",
    "    nutrient_dict = {} \n",
    "\n",
    "    counter = 0\n",
    "    for blob_cord in text_blob_list:\n",
    "        if debug:\n",
    "            counter += 1\n",
    "            word_image = crop(cropped_image_cv, blob_cord, os.path.join(debug_folder, \"{}.jpg\".format(counter)), 0.005, True)\n",
    "        else:\n",
    "            word_image = crop(cropped_image_cv, blob_cord, \"\", 0.005, False)\n",
    "\n",
    "        if word_image.size == 0:\n",
    "            continue\n",
    "\n",
    "        word_image = preprocess_for_ocr(word_image)\n",
    "        if (word_image.shape[1] > 0 and word_image.shape[0] > 0):\n",
    "            text = ocr(word_image, 1, 7)\n",
    "\n",
    "            if debug:\n",
    "                print(text)\n",
    "\n",
    "            if text:\n",
    "                center_x = (blob_cord[0] + blob_cord[2]) / 2\n",
    "                center_y = (blob_cord[1] + blob_cord[3]) / 2\n",
    "                box_center = (center_x, center_y)\n",
    "\n",
    "                new_location = {\n",
    "                    'bbox': blob_cord,\n",
    "                    'text': text,\n",
    "                    'box_center': box_center,\n",
    "                    'string_type': string_type(text)\n",
    "                }\n",
    "                text_location_list.append(new_location)\n",
    "    for text_dict in text_location_list:\n",
    "        if text_dict['string_type'] == 2:\n",
    "            for text_dict_test in text_location_list:\n",
    "                if position_definer(text_dict['box_center'][1], text_dict_test['bbox'][1], text_dict_test['bbox'][3]) and text_dict_test['string_type'] == 1:\n",
    "                    text_dict['text'] += ' ' + text_dict_test['text']\n",
    "                    text_dict['string_type'] = 0\n",
    "\n",
    "    fuzdict = make_fuzdict('data/nutrients.txt')\n",
    "    for text_dict in text_location_list:\n",
    "        if text_dict['string_type'] == 0:\n",
    "            text = clean_string(text_dict['text'])\n",
    "            if fuz_check_for_label(text, fuzdict, debug):\n",
    "                label_name, label_value = get_fuz_label_from_string(text, fuzdict, debug)\n",
    "                nutrient_dict[label_name] = separate_unit(label_value)\n",
    "\n",
    "    if debug:\n",
    "        time_taken = time.time() - start_time\n",
    "        print(\"Total Time Taken: %.5fs\" % time_taken)\n",
    "\n",
    "    return nutrient_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detection(image_path, cropper_model_path, debug=False):\n",
    "    cropper_model = tf.keras.models.load_model(cropper_model_path, custom_objects={'IoULoss': IoULoss})\n",
    "    image_cropper = ImageCropper(model=cropper_model)\n",
    "    cropped_image = image_cropper.process_image(image_path)\n",
    "    if debug:\n",
    "        debug_folder = 'C:/Users/koust_fiminqv/Desktop/thesis/debug'\n",
    "        os.makedirs(debug_folder, exist_ok=True)\n",
    "        cropped_image_path = os.path.join(debug_folder, 'cropped_image.jpg')\n",
    "        cropped_image.save(cropped_image_path)\n",
    "\n",
    "    load_text_model()\n",
    "    nutrient_dict = detect(cropped_image, debug)\n",
    "    return nutrient_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "WARNING:tensorflow:From c:\\Users\\koust_fiminqv\\Desktop\\thesis\\text_detection\\text_detection_class.py:15: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "Text Weights Loaded!\n",
      "        Nutrient      Value\n",
      "0           Salt  (16.0, g)\n",
      "1        Protein   (2.7, g)\n",
      "2      Total Fat  (16.9, g)\n",
      "3         Sugars  (12.6, g)\n",
      "4  Saturated Fat   (3.3, g)\n"
     ]
    }
   ],
   "source": [
    "image_path = 'C:/Users/koust_fiminqv/Desktop/thesis/test_image/test3.jpg'\n",
    "cropper_model_path = 'C:/Users/koust_fiminqv/Desktop/thesis/models/resnet_tuned_model.h5'\n",
    "debug = False  \n",
    "\n",
    "nutrient_dict = run_detection(image_path, cropper_model_path, debug)\n",
    "df = pd.DataFrame(list(nutrient_dict.items()), columns=['Nutrient', 'Value'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
